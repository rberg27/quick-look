{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rberg\\Anaconda3\\envs\\seg-env-win-friendly\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32m2025-05-04 21:09:19.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miopaint.helper\u001b[0m:\u001b[36mload_jit_model\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mLoading model from: C:\\Users\\rberg/.cache\\torch\\hub\\checkpoints\\big-lama.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "LaMa model loaded successfully\n",
      "iopaint version: 1.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rberg\\AppData\\Local\\Temp\\ipykernel_22164\\4044462445.py:38: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved successfully to ./test-lama.png\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "from config import PROCESSED_DATASET_PATH\n",
    "\n",
    "# Try to import LaMa-specific modules\n",
    "try:\n",
    "    print(torch.cuda.is_available())\n",
    "    from iopaint.model import LaMa\n",
    "    from iopaint.schema import InpaintRequest, LDMSampler\n",
    "\n",
    "    config = InpaintRequest(\n",
    "    mask_strategy=\"custom\",\n",
    "    ldm_steps=50,  # Adjust as needed\n",
    "    ldm_sampler=LDMSampler.ddim,  # or other sampler options\n",
    "    hd_strategy=\"Original\",  # or \"Resize\", \"Crop\"\n",
    "    hd_strategy_crop_margin=32,\n",
    "    hd_strategy_crop_trigger_size=512,\n",
    "    hd_strategy_resize_limit=512\n",
    "    )\n",
    "    \n",
    "    # Check if CUDA is available\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Initialize the LaMa model\n",
    "    model = LaMa(device=device)\n",
    "    print(\"LaMa model loaded successfully\")\n",
    "    \n",
    "    # Print version information\n",
    "    import pkg_resources\n",
    "    iopaint_version = pkg_resources.get_distribution(\"iopaint\").version\n",
    "    print(f\"iopaint version: {iopaint_version}\")\n",
    "    \n",
    "    # Test with a sample image\n",
    "    # You can replace this with an actual image path\n",
    "    sample_image_path = r\"C:\\Users\\rberg\\Documents\\quick-look\\data\\filtered_dataset\\processed\\masked\\000000000110.png\" #provide the masked image\n",
    "    sample_mask_path = r\"C:\\Users\\rberg\\Documents\\quick-look\\data\\filtered_dataset\\processed\\masks\\000000000110.png\"\n",
    "    sample_output_path = \"./test-lama.png\"\n",
    "\n",
    "    \n",
    "    if os.path.exists(sample_image_path):\n",
    "        # Load the image\n",
    "        image = cv2.imread(sample_image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Create a simple mask (white rectangle in the middle)\n",
    "        mask = cv2.imread(sample_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        height, width = image.shape[:2]\n",
    "        mask_width, mask_height = width // 3, height // 3\n",
    "        x1, y1 = width // 3, height // 3\n",
    "        x2, y2 = 2 * width // 3, 2 * height // 3\n",
    "        \n",
    "        \n",
    "        # Inpaint the image\n",
    "        result = model(image, mask, config)\n",
    "        \n",
    "        # Create a canvas for displaying all images side by side\n",
    "        height, width = image.shape[:2]\n",
    "        canvas = np.zeros((height, width * 3, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Add original image to the canvas\n",
    "        canvas[:, 0:width] = image\n",
    "        \n",
    "        # Add mask to the canvas (convert grayscale to RGB for display)\n",
    "        mask_rgb = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n",
    "        canvas[:, width:width*2] = mask_rgb\n",
    "        \n",
    "        # Add inpainted result to the canvas\n",
    "        canvas[:, width*2:width*3] = result\n",
    "        \n",
    "        # Add titles\n",
    "        title_height = 30\n",
    "        title_canvas = np.ones((title_height, width * 3, 3), dtype=np.uint8) * 255\n",
    "        \n",
    "        # Add text for titles\n",
    "        cv2.putText(title_canvas, \"Original Image\", (width//2 - 70, 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "        cv2.putText(title_canvas, \"Mask\", (width + width//2 - 30, 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "        cv2.putText(title_canvas, \"Inpainted Result\", (width*2 + width//2 - 80, 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "        \n",
    "        # Combine title and images\n",
    "        display_image = np.vstack((title_canvas, canvas))\n",
    "        \n",
    "        # Save the combined image\n",
    "        cv2.imwrite(sample_output_path, cv2.cvtColor(display_image, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        print(f\"Image saved successfully to {sample_output_path}\")\n",
    "    else:\n",
    "        print(f\"Sample image not found at {sample_image_path}\")\n",
    "        print(\"Please update the path to test with your own image\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"LaMa dependencies not installed: {e}\")\n",
    "    print(\"Please install iopaint package with: pip install iopaint\")\n",
    "    print(f\"Full error: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 21:21:23.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miopaint.helper\u001b[0m:\u001b[36mload_jit_model\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mLoading model from: C:\\Users\\rberg/.cache\\torch\\hub\\checkpoints\\diffusion.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 21:21:25.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miopaint.helper\u001b[0m:\u001b[36mload_jit_model\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mLoading model from: C:\\Users\\rberg/.cache\\torch\\hub\\checkpoints\\cond_stage_model_decode.pt\u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:25.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miopaint.helper\u001b[0m:\u001b[36mload_jit_model\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mLoading model from: C:\\Users\\rberg/.cache\\torch\\hub\\checkpoints\\cond_stage_model_encode.pt\u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:25.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miopaint.model.ddim_sampler\u001b[0m:\u001b[36mddim_sampling\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mRunning DDIM Sampling with 50 timesteps\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iopaint version: 1.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [00:14<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved successfully to ./test-ldm.png\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "from config import PROCESSED_DATASET_PATH\n",
    "\n",
    "from iopaint.model import LDM\n",
    "from iopaint.schema import InpaintRequest, LDMSampler\n",
    "\n",
    "# Try to import LaMa-specific modules\n",
    "try:\n",
    "    print(torch.cuda.is_available())\n",
    "    from iopaint.model import LDM\n",
    "    from iopaint.schema import InpaintRequest, LDMSampler\n",
    "\n",
    "    # Initialize LDM model (Stable Diffusion)\n",
    "    model = LDM(name=\"sd1.5\", device=\"cpu\" if not torch.cuda.is_available() else \"cuda\")\n",
    "\n",
    "    \n",
    "    # Create inpaint request with text prompt\n",
    "    request = InpaintRequest(\n",
    "        mask_strategy=\"custom\",\n",
    "        prompt=\"chair\",\n",
    "        negative_prompt=\"blurry, bad quality\",\n",
    "        ldm_sampler=LDMSampler.ddim,  # Choose sampler\n",
    "        ldm_steps=50,\n",
    "        hd_strategy=\"Original\"\n",
    "    )\n",
    "    \n",
    "    # Print version information\n",
    "    import pkg_resources\n",
    "    iopaint_version = pkg_resources.get_distribution(\"iopaint\").version\n",
    "    print(f\"iopaint version: {iopaint_version}\")\n",
    "    \n",
    "    # Test with a sample image\n",
    "    # You can replace this with an actual image path\n",
    "    sample_image_path = r\"C:\\Users\\rberg\\Documents\\quick-look\\data\\filtered_dataset\\processed\\masked\\000000000110.png\" #provide the masked image\n",
    "    sample_mask_path = r\"C:\\Users\\rberg\\Documents\\quick-look\\data\\filtered_dataset\\processed\\masks\\000000000110.png\"\n",
    "    sample_output_path = \"./test-ldm.png\"\n",
    "\n",
    "    \n",
    "    if os.path.exists(sample_image_path):\n",
    "        # Load the image\n",
    "        image = cv2.imread(sample_image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Create a simple mask (white rectangle in the middle)\n",
    "        mask = cv2.imread(sample_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Inpaint the image - directly use numpy array\n",
    "        result = model(image, mask, request)\n",
    "        \n",
    "        # Convert result back to numpy array if needed\n",
    "        if not isinstance(result, np.ndarray):\n",
    "            result = np.array(result)\n",
    "        \n",
    "        # Swap the R and B channels of the result image\n",
    "        # In RGB format, channels are ordered as [R, G, B] with indices [0, 1, 2]\n",
    "        # We'll create a copy to avoid modifying the original array\n",
    "        result_rb_swapped = result.copy()\n",
    "        \n",
    "        # Swap R (index 0) and B (index 2) channels\n",
    "        result_rb_swapped[:, :, 0] = result[:, :, 2]  # R becomes B\n",
    "        result_rb_swapped[:, :, 2] = result[:, :, 0]  # B becomes R\n",
    "        \n",
    "        # Update the result with the R-B swapped version\n",
    "        result = result_rb_swapped\n",
    "        # Create a canvas for displaying all images side by side\n",
    "        height, width = image.shape[:2]\n",
    "        canvas = np.zeros((height, width * 3, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Add original image to the canvas\n",
    "        canvas[:, 0:width] = image\n",
    "        \n",
    "        # Add mask to the canvas (convert grayscale to RGB for display)\n",
    "        mask_rgb = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n",
    "        canvas[:, width:width*2] = mask_rgb\n",
    "        \n",
    "        # Add inpainted result to the canvas\n",
    "        canvas[:, width*2:width*3] = result\n",
    "        \n",
    "        # Add titles\n",
    "        title_height = 30\n",
    "        title_canvas = np.ones((title_height, width * 3, 3), dtype=np.uint8) * 255\n",
    "        \n",
    "        # Add text for titles\n",
    "        cv2.putText(title_canvas, \"Original Image\", (width//2 - 70, 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "        cv2.putText(title_canvas, \"Mask\", (width + width//2 - 30, 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "        cv2.putText(title_canvas, \"Inpainted Result\", (width*2 + width//2 - 80, 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "        \n",
    "        # Combine title and images\n",
    "        display_image = np.vstack((title_canvas, canvas))\n",
    "        \n",
    "        # Save the combined image\n",
    "        cv2.imwrite(sample_output_path, cv2.cvtColor(display_image, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        print(f\"Image saved successfully to {sample_output_path}\")\n",
    "    else:\n",
    "        print(f\"Sample image not found at {sample_image_path}\")\n",
    "        print(\"Please update the path to test with your own image\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"LaMa dependencies not installed: {e}\")\n",
    "    print(\"Please install iopaint package with: pip install iopaint\")\n",
    "    print(f\"Full error: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "class LamaGapFiller:\n",
    "    \"\"\"\n",
    "    Gap filling using LaMa (Large Mask Inpainting) model via iopaint.\n",
    "    \"\"\"\n",
    "    def __init__(self, device=None):\n",
    "        \"\"\"\n",
    "        Initialize the LaMa gap filler.\n",
    "        \n",
    "        Args:\n",
    "            device: Device to run the model on ('cuda' or 'cpu')\n",
    "        \"\"\"\n",
    "        self.device = device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self._load_model()\n",
    "    \n",
    "    def _load_model(self):\n",
    "        try:\n",
    "            # Import LaMa-specific modules\n",
    "            from iopaint.model import LDM\n",
    "            from iopaint.schema import InpaintRequest, LDMSampler\n",
    "            \n",
    "            # Initialize LDM model (Stable Diffusion)\n",
    "            self.model = LDM(name=\"sd1.5\", device=self.device)\n",
    "            \n",
    "            # Create inpaint request with text prompt\n",
    "            self.request = InpaintRequest(\n",
    "                mask_strategy=\"custom\",\n",
    "                prompt=\"chair\",\n",
    "                negative_prompt=\"blurry, bad quality\",\n",
    "                ldm_sampler=LDMSampler.ddim,\n",
    "                ldm_steps=50,\n",
    "                hd_strategy=\"Original\"\n",
    "            )\n",
    "            \n",
    "            print(\"LDM model loaded successfully\")\n",
    "        except ImportError as e:\n",
    "            print(f\"iopaint dependencies not installed: {e}\")\n",
    "            self.model = None\n",
    "    \n",
    "    def fill_gap(self, image_with_gap, mask=None):\n",
    "        \"\"\"\n",
    "        Fill the gap using LDM inpainting model.\n",
    "        \n",
    "        Args:\n",
    "            image_with_gap: Image with a gap to be filled (numpy array, RGB)\n",
    "            mask: Binary mask indicating the gap region (1 for gap, 0 for known regions)\n",
    "            \n",
    "        Returns:\n",
    "            Completed image with the gap filled\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            print(\"Model not loaded. Returning original image.\")\n",
    "            return image_with_gap\n",
    "        \n",
    "        # Ensure mask is in the correct format\n",
    "        if mask is None:\n",
    "            # Try to detect the gap automatically (assuming white/light gray areas)\n",
    "            gray = cv2.cvtColor(image_with_gap, cv2.COLOR_RGB2GRAY)\n",
    "            mask = np.zeros_like(gray)\n",
    "            mask[(gray > 240)] = 255  # Adjust threshold as needed\n",
    "        else:\n",
    "            # Convert binary mask (0-1) to grayscale (0-255) if needed\n",
    "            if mask.max() <= 1:\n",
    "                mask = (mask * 255).astype(np.uint8)\n",
    "        \n",
    "        # Inpaint the image\n",
    "        result = self.model(image_with_gap, mask, self.request)\n",
    "        \n",
    "        # Convert result back to numpy array if needed\n",
    "        if not isinstance(result, np.ndarray):\n",
    "            result = np.array(result)\n",
    "        \n",
    "        # Swap the R and B channels of the result image\n",
    "        # In RGB format, channels are ordered as [R, G, B] with indices [0, 1, 2]\n",
    "        result_rb_swapped = result.copy()\n",
    "        result_rb_swapped[:, :, 0] = result[:, :, 2]  # R becomes B\n",
    "        result_rb_swapped[:, :, 2] = result[:, :, 0]  # B becomes R\n",
    "        \n",
    "        return result_rb_swapped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'model_info'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01miopaint\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PaintByExample\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Initialize PaintByExample model\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mPaintByExample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Print version information\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpkg_resources\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rberg\\Anaconda3\\envs\\seg-env-win-friendly\\lib\\site-packages\\iopaint\\model\\base.py:275\u001b[0m, in \u001b[0;36mDiffusionInpaintModel.__init__\u001b[1;34m(self, device, **kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, device, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 275\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_info \u001b[38;5;241m=\u001b[39m \u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_info\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id_or_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_info\u001b[38;5;241m.\u001b[39mpath\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(device, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'model_info'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "from config import PROCESSED_DATASET_PATH\n",
    "\n",
    "# Try to import iopaint modules\n",
    "try:\n",
    "    print(torch.cuda.is_available())\n",
    "    from iopaint.model import PaintByExample\n",
    "    \n",
    "    # Initialize PaintByExample model\n",
    "    model = PaintByExample(device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Print version information\n",
    "    import pkg_resources\n",
    "    iopaint_version = pkg_resources.get_distribution(\"iopaint\").version\n",
    "    print(f\"iopaint version: {iopaint_version}\")\n",
    "    \n",
    "    # Test with sample images\n",
    "    sample_image_path = r\"C:\\Users\\rberg\\Documents\\quick-look\\data\\filtered_dataset\\processed\\masked\\000000000110.png\" # masked image\n",
    "    sample_mask_path = r\"C:\\Users\\rberg\\Documents\\quick-look\\data\\filtered_dataset\\processed\\masks\\000000000110.png\"\n",
    "    # Example image path - this is the reference image that contains what we want to paint\n",
    "    example_image_path = r\"C:\\Users\\rberg\\Documents\\quick-look\\data\\misc_files\\chair.jpg\"\n",
    "    sample_output_path = \"./test-paintbyexample.png\"\n",
    "    \n",
    "    if os.path.exists(sample_image_path) and os.path.exists(example_image_path):\n",
    "        # Load the image\n",
    "        image = cv2.imread(sample_image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Load the example image\n",
    "        example_image = cv2.imread(example_image_path)\n",
    "        example_image = cv2.cvtColor(example_image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Load the mask\n",
    "        mask = cv2.imread(sample_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Inpaint the image using PaintByExample\n",
    "        result = model(image, mask, example_image=example_image)\n",
    "        \n",
    "        # Convert result back to numpy array if needed\n",
    "        if not isinstance(result, np.ndarray):\n",
    "            result = np.array(result)\n",
    "        \n",
    "        # Swap the R and B channels of the result image\n",
    "        # In RGB format, channels are ordered as [R, G, B] with indices [0, 1, 2]\n",
    "        # We'll create a copy to avoid modifying the original array\n",
    "        result_rb_swapped = result.copy()\n",
    "        \n",
    "        # Swap R (index 0) and B (index 2) channels\n",
    "        result_rb_swapped[:, :, 0] = result[:, :, 2]  # R becomes B\n",
    "        result_rb_swapped[:, :, 2] = result[:, :, 0]  # B becomes R\n",
    "        \n",
    "        # Update the result with the R-B swapped version\n",
    "        result = result_rb_swapped\n",
    "        # Create a canvas for displaying all images side by side\n",
    "        height, width = image.shape[:2]\n",
    "        canvas = np.zeros((height, width * 4, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Add original image to the canvas\n",
    "        canvas[:, 0:width] = image\n",
    "        \n",
    "        # Add mask to the canvas (convert grayscale to RGB for display)\n",
    "        mask_rgb = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n",
    "        canvas[:, width:width*2] = mask_rgb\n",
    "        \n",
    "        # Add example image to the canvas\n",
    "        canvas[:, width*2:width*3] = example_image\n",
    "        \n",
    "        # Add inpainted result to the canvas\n",
    "        canvas[:, width*3:width*4] = result\n",
    "        \n",
    "        # Add titles\n",
    "        title_height = 30\n",
    "        title_canvas = np.ones((title_height, width * 4, 3), dtype=np.uint8) * 255\n",
    "        \n",
    "        # Add text for titles\n",
    "        cv2.putText(title_canvas, \"Original Image\", (width//2 - 70, 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "        cv2.putText(title_canvas, \"Mask\", (width + width//2 - 30, 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "        cv2.putText(title_canvas, \"Example Image\", (width*2 + width//2 - 70, 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "        cv2.putText(title_canvas, \"Inpainted Result\", (width*3 + width//2 - 80, 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "        \n",
    "        # Combine title and images\n",
    "        display_image = np.vstack((title_canvas, canvas))\n",
    "        \n",
    "        # Save the combined image\n",
    "        cv2.imwrite(sample_output_path, cv2.cvtColor(display_image, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        print(f\"Image saved successfully to {sample_output_path}\")\n",
    "    else:\n",
    "        print(f\"Sample image not found at {sample_image_path} or example image not found at {example_image_path}\")\n",
    "        print(\"Please update the paths to test with your own images\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"iopaint dependencies not installed: {e}\")\n",
    "    print(\"Please install iopaint package with: pip install iopaint\")\n",
    "    print(f\"Full error: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "from config import PROCESSED_DATASET_PATH\n",
    "\n",
    "# Try to import PaintByExample-specific modules\n",
    "try:\n",
    "    print(torch.cuda.is_available())\n",
    "    from iopaint.model import PaintByExample\n",
    "    from iopaint.schema import InpaintRequest\n",
    "\n",
    "    # Initialize PaintByExample model\n",
    "    device = \"cpu\" if not torch.cuda.is_available() else \"cuda\"\n",
    "    \n",
    "    # PaintByExample requires a reference image instead of a text prompt\n",
    "    model = PaintByExample(device=device)\n",
    "    \n",
    "    # Print version information\n",
    "    import pkg_resources\n",
    "    iopaint_version = pkg_resources.get_distribution(\"iopaint\").version\n",
    "    print(f\"iopaint version: {iopaint_version}\")\n",
    "    \n",
    "   # Test with sample images\n",
    "    sample_image_path = r\"C:\\Users\\rberg\\Documents\\quick-look\\data\\filtered_dataset\\processed\\masked\\000000000110.png\" # masked image\n",
    "    sample_mask_path = r\"C:\\Users\\rberg\\Documents\\quick-look\\data\\filtered_dataset\\processed\\masks\\000000000110.png\"\n",
    "    # Example image path - this is the reference image that contains what we want to paint\n",
    "    reference_image_path = r\"C:\\Users\\rberg\\Documents\\quick-look\\data\\misc_files\\chair.jpg\"\n",
    "    sample_output_path = \"./test-paintbyexample.png\"\n",
    "    \n",
    "    # Load the reference image (this will be used as the example)\n",
    "    if not os.path.exists(reference_image_path):\n",
    "        print(f\"Reference image not found at {reference_image_path}\")\n",
    "        print(\"Please provide a path to a reference image\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    reference_image = cv2.imread(reference_image_path)\n",
    "    reference_image = cv2.cvtColor(reference_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    if os.path.exists(sample_image_path):\n",
    "        # Load the image to be inpainted\n",
    "        image = cv2.imread(sample_image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Load the mask\n",
    "        mask = cv2.imread(sample_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Create inpaint request\n",
    "        request = InpaintRequest(\n",
    "            mask_strategy=\"custom\",\n",
    "            hd_strategy=\"Original\"\n",
    "        )\n",
    "        \n",
    "        # Inpaint the image using the reference image\n",
    "        # PaintByExample takes: image, mask, reference_image\n",
    "        result = model.forward(image, mask, reference_image, request)\n",
    "        \n",
    "        # Convert result back to numpy array if needed\n",
    "        if not isinstance(result, np.ndarray):\n",
    "            result = np.array(result)\n",
    "        \n",
    "        # Create a canvas for displaying all images side by side\n",
    "        height, width = image.shape[:2]\n",
    "        canvas = np.zeros((height, width * 4, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Resize reference image to match height if needed\n",
    "        if reference_image.shape[0] != height:\n",
    "            aspect_ratio = reference_image.shape[1] / reference_image.shape[0]\n",
    "            new_width = int(height * aspect_ratio)\n",
    "            reference_image_resized = cv2.resize(reference_image, (new_width, height))\n",
    "        else:\n",
    "            reference_image_resized = reference_image\n",
    "        \n",
    "        # Add original image to the canvas\n",
    "        canvas[:, 0:width] = image\n",
    "        \n",
    "        # Add mask to the canvas (convert grayscale to RGB for display)\n",
    "        mask_rgb = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n",
    "        canvas[:, width:width*2] = mask_rgb\n",
    "        \n",
    "        # Add reference image to the canvas\n",
    "        canvas[:, width*2:width*3] = reference_image_resized[:, :width]  # Crop if needed\n",
    "        \n",
    "        # Add inpainted result to the canvas\n",
    "        canvas[:, width*3:width*4] = result\n",
    "        \n",
    "        # Add titles\n",
    "        title_height = 30\n",
    "        title_canvas = np.ones((title_height, width * 4, 3), dtype=np.uint8) * 255\n",
    "        \n",
    "        # Add text for titles\n",
    "        cv2.putText(title_canvas, \"Original Image\", (width//2 - 70, 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "        cv2.putText(title_canvas, \"Mask\", (width + width//2 - 30, 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "        cv2.putText(title_canv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 21:41:39.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miopaint.model_manager\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mLoading model: Fantasy-Studio/Paint-by-Example\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Error: Unsupported model: Fantasy-Studio/Paint-by-Example. Available models: ['lama', 'ldm', 'cv2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rberg\\AppData\\Local\\Temp\\ipykernel_22164\\1165173705.py\", line 24, in <module>\n",
      "    model = ModelManager(\n",
      "  File \"c:\\Users\\rberg\\Anaconda3\\envs\\seg-env-win-friendly\\lib\\site-packages\\iopaint\\model_manager.py\", line 40, in __init__\n",
      "    self.model = self.init_model(name, device, **kwargs)\n",
      "  File \"c:\\Users\\rberg\\Anaconda3\\envs\\seg-env-win-friendly\\lib\\site-packages\\iopaint\\model_manager.py\", line 49, in init_model\n",
      "    raise NotImplementedError(\n",
      "NotImplementedError: Unsupported model: Fantasy-Studio/Paint-by-Example. Available models: ['lama', 'ldm', 'cv2']\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "from config import PROCESSED_DATASET_PATH\n",
    "\n",
    "# Try to import PaintByExample-specific modules\n",
    "try:\n",
    "    print(torch.cuda.is_available())\n",
    "    from iopaint.model_manager import ModelManager\n",
    "    from iopaint.schema import InpaintRequest\n",
    "    from iopaint.model.paint_by_example import PaintByExample\n",
    "\n",
    "\n",
    "    # Initialize PaintByExample model using ModelManager\n",
    "    device = \"cpu\" if not torch.cuda.is_available() else \"cuda\"\n",
    "    \n",
    "    # Create model using ModelManager with PaintByExample model name\n",
    "    model = ModelManager(\n",
    "        name=PaintByExample.name,\n",
    "        device=device,\n",
    "        disable_nsfw=False,\n",
    "        disable_nsfw_checker=False\n",
    "    )\n",
    "    \n",
    "    # Print version information\n",
    "    import pkg_resources\n",
    "    iopaint_version = pkg_resources.get_distribution(\"iopaint\").version\n",
    "    print(f\"iopaint version: {iopaint_version}\")\n",
    "    \n",
    "    # Paths to your files\n",
    "    sample_image_path = r\"C:\\Users\\rberg\\Documents\\quick-look\\data\\filtered_dataset\\processed\\masked\\000000000110.png\"  # Image to inpaint\n",
    "    sample_mask_path = r\"C:\\Users\\rberg\\Documents\\quick-look\\data\\filtered_dataset\\processed\\masks\\000000000110.png\"     # Mask showing area to inpaint\n",
    "    reference_image_path = r\"C:\\path\\to\\reference\\image.png\"  # Reference image for PaintByExample\n",
    "    sample_output_path = \"./test-paintbyexample.png\"\n",
    "    \n",
    "    # Load the reference image (this will be used as the example)\n",
    "    if not os.path.exists(reference_image_path):\n",
    "        print(f\"Reference image not found at {reference_image_path}\")\n",
    "        print(\"Please provide a path to a reference image\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    reference_image = cv2.imread(reference_image_path)\n",
    "    reference_image = cv2.cvtColor(reference_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    if os.path.exists(sample_image_path):\n",
    "        # Load the image to be inpainted\n",
    "        image = cv2.imread(sample_image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Load the mask\n",
    "        mask = cv2.imread(sample_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Create inpaint request\n",
    "        request = InpaintRequest(\n",
    "            mask_strategy=\"custom\",\n",
    "            hd_strategy=\"Original\"\n",
    "        )\n",
    "        \n",
    "        # Inpaint the image using the reference image\n",
    "        # Use the ModelManager's forward method\n",
    "        # PaintByExample requires passing the request with the image by example\n",
    "        # We need to set the reference image in the request\n",
    "        request.example_image = reference_image\n",
    "        \n",
    "        result = model(image=image, mask=mask, request=request)\n",
    "        \n",
    "        # Convert result back to numpy array if needed\n",
    "        if not isinstance(result, np.ndarray):\n",
    "            result = np.array(result)\n",
    "        \n",
    "        # Create a canvas for displaying all images side by side\n",
    "        height, width = image.shape[:2]\n",
    "        canvas = np.zeros((height, width * 4, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Resize reference image to match height if needed\n",
    "        if reference_image.shape[0] != height:\n",
    "            aspect_ratio = reference_image.shape[1] / reference_image.shape[0]\n",
    "            new_width = int(height * aspect_ratio)\n",
    "            reference_image_resized = cv2.resize(reference_image, (new_width, height))\n",
    "        else:\n",
    "            reference_image_resized = reference_image\n",
    "        \n",
    "        # Add original image to the canvas\n",
    "        canvas[:, 0:width] = image\n",
    "        \n",
    "        # Add mask to the canvas (convert grayscale to RGB for display)\n",
    "        mask_rgb = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n",
    "        canvas[:, width:width*2] = mask_rgb\n",
    "        \n",
    "        # Add reference image to the canvas\n",
    "        canvas[:, width*2:width*3] = reference_image_resized[:, :width]  # Crop if needed\n",
    "        \n",
    "        # Add inpainted result to the canvas\n",
    "        canvas[:, width*3:width*4] = result\n",
    "        \n",
    "        # Add titles\n",
    "        title_height = 30\n",
    "        title_canvas = np.ones((title_height, width * 4, 3), dtype=np.uint8) * 255\n",
    "        \n",
    "        # Add text for titles\n",
    "        cv2.putText(title_canvas, \"Original Image\", (width//2 - 70, 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "        cv2.putText(title_canvas, \"Mask\", (width + width//2 - 30, 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "        cv2.putText(title_canvas, \"Reference Image\", (width*2 + width//2 - 80, 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "        cv2.putText(title_canvas, \"Inpainted Result\", (width*3 + width//2 - 80, 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "        \n",
    "        # Combine title and images\n",
    "        display_image = np.vstack((title_canvas, canvas))\n",
    "        \n",
    "        # Save the combined image\n",
    "        cv2.imwrite(sample_output_path, cv2.cvtColor(display_image, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        print(f\"Image saved successfully to {sample_output_path}\")\n",
    "    else:\n",
    "        print(f\"Sample image not found at {sample_image_path}\")\n",
    "        print(\"Please update the path to test with your own image\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"PaintByExample dependencies not installed: {e}\")\n",
    "    print(\"Please install iopaint package with: pip install iopaint\")\n",
    "    print(f\"Full error: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.3.1\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "FlashAttention available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"FlashAttention available: {torch.backends.cuda.flash_sdp_enabled()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved inpainted image to ./byo_gan_results\\report-images\\inpainted_1.jpg\n",
      "Saved mask image to ./byo_gan_results\\report-images\\mask_1.jpg\n",
      "Saved masked image to ./byo_gan_results\\report-images\\masked_1.jpg\n",
      "Saved inpainted image to ./byo_gan_results\\report-images\\inpainted_2.jpg\n",
      "Saved mask image to ./byo_gan_results\\report-images\\mask_2.jpg\n",
      "Saved masked image to ./byo_gan_results\\report-images\\masked_2.jpg\n",
      "Saved inpainted image to ./byo_gan_results\\report-images\\inpainted_3.jpg\n",
      "Saved mask image to ./byo_gan_results\\report-images\\mask_3.jpg\n",
      "Saved masked image to ./byo_gan_results\\report-images\\masked_3.jpg\n",
      "Saved inpainted image to ./byo_gan_results\\report-images\\inpainted_4.jpg\n",
      "Saved mask image to ./byo_gan_results\\report-images\\mask_4.jpg\n",
      "Saved masked image to ./byo_gan_results\\report-images\\masked_4.jpg\n",
      "Saved inpainted image to ./byo_gan_results\\report-images\\inpainted_5.jpg\n",
      "Saved mask image to ./byo_gan_results\\report-images\\mask_5.jpg\n",
      "Saved masked image to ./byo_gan_results\\report-images\\masked_5.jpg\n"
     ]
    }
   ],
   "source": [
    "inpainted_dir = config.INPAINTED_DATASET_PATH\n",
    "mask_dir = config.MASKS_DATASET_PATH\n",
    "masked_dir = config.MASKED_DATASET_PATH\n",
    "original_dir = config.ORIGINAL_DATASET_PATH\n",
    "\n",
    "file_names = ['000000469300.png', '000000251082.png', '000000048340.png', '000000100726.png', '000000136790.png']\n",
    "\n",
    "for i, file_name in enumerate(file_names):\n",
    "    inpainted_path = os.path.join(inpainted_dir, file_name)\n",
    "    mask_path = os.path.join(mask_dir, file_name)\n",
    "    masked_path = os.path.join(masked_dir, file_name)\n",
    "    original_path = os.path.join(original_dir, file_name)\n",
    "\n",
    "    inpainted_image = cv2.imread(inpainted_path)\n",
    "    mask_image = cv2.imread(mask_path)\n",
    "    masked_image = cv2.imread(masked_path)\n",
    "    original_image = cv2.imread(original_path)\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = os.path.join(\"./byo_gan_results\", \"report-images\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Get index from filename (assuming it's in the loop)\n",
    "    i = file_names.index(file_name)\n",
    "    \n",
    "    # Save inpainted image\n",
    "    inpainted_output_path = os.path.join(output_dir, f\"inpainted_{i+1}.jpg\")\n",
    "    cv2.imwrite(inpainted_output_path, inpainted_image)\n",
    "    \n",
    "    # Save mask image\n",
    "    mask_output_path = os.path.join(output_dir, f\"mask_{i+1}.jpg\")\n",
    "    cv2.imwrite(mask_output_path, mask_image)\n",
    "\n",
    "    masked_output_path = os.path.join(output_dir, f\"masked_{i+1}.jpg\")\n",
    "    cv2.imwrite(masked_output_path, masked_image)\n",
    "    \n",
    "    original_output_path = os.path.join(output_dir, f\"original_{i+1}.jpg\")\n",
    "    cv2.imwrite(original_output_path, original_image)\n",
    "\n",
    "    print(f\"Saved inpainted image to {inpainted_output_path}\")\n",
    "    print(f\"Saved mask image to {mask_output_path}\")\n",
    "    print(f\"Saved masked image to {masked_output_path}\")\n",
    "    print(f\"Saved original image to {original_output_path}\")\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seg-env-win-friendly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
